{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT in Python\n",
    "\n",
    "In this tutorial, you will learn how to use a very unique library in python: tpot . The reason why this library is unique is that it automates the entire Machine Learning pipeline and provides you with the best performing machine learning model. More specifically, you will learn:\n",
    "\n",
    "- The idea behind Automated Machine Learning\n",
    "- How TPOT uses Genetic Programming to select the best machine learning model\n",
    "- Using TPOT on a dataset in Python\n",
    "- Limitations of TPOT\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "Original post is [here](https://www.datacamp.com/community/tutorials/tpot-machine-learning-python) - many thanks to DataCamp!\n",
    "\n",
    "Revised by Dr. Jie Tao, Sep-25-2018, Ver. 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Introduction\n",
    "\n",
    "There are a lot of components you have to consider before solving a machine learning problem some of which includes *data preparation*, *feature selection*, *feature engineering*, *model selection and validation*, *hyperparameter tuning*, etc. \n",
    "\n",
    "In theory, you can find and apply a plethora of techniques for each of these components, but they all might perform differently for different datasets. The challenge is to find the best performing combination of techniques so that you can minimize the error in your predictions. This is the main reason that nowadays people are working to develop **Auto-ML algorithms** and platforms so that anyone, without any machine learning expertise, can build models without spending much time or effort. \n",
    "\n",
    "One such platform is available as a python library: **TPOT**. You can consider **TPOT** your Data Science Assistant. TPOT is a python Automated Machine Learning tool that optimizes *machine learning pipelines* using genetic programming. It will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data.\n",
    "\n",
    "Following image depicts how TPOT works:\n",
    "\n",
    "<img src = 'https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1537396029/output_2_0_d7uh0v.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "To install tpot on your system, you can run the command **sudo pip install tpot** on command line terminal or check out this [link](http://epistasislab.github.io/tpot/installing/). tpot is built on top of several existing Python libraries, including **numpy**, **scipy**, **scikit-learn**, **DEAP**, **update_checker**, **tqdm**, **stopit**, and **pandas**. Most of the necessary Python packages can be installed via the [Anaconda Python distribution](https://www.continuum.io/downloads), or you could install them separately also. Optionally, you can also install **XGBoost** [here](https://www.datacamp.com/community/tutorials/xgboost-in-python) if you would like tpot to use the eXtreme Gradient Boosting models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Programming\n",
    "With the right data, computing power and machine learning model you can discover a solution to any problem, but knowing which model to use can be challenging for you as there are so many of them like *Decision Trees*, *SVM*, *KNN*, etc. That's where genetic programming can be of great use and provide help. Genetic algorithms are inspired by the Darwinian process of Natural Selection, and they are used to generate solutions to optimization and search problems in computer science.\n",
    "\n",
    "Broadly speaking, Genetic Algorithms have three properties:\n",
    "\n",
    "- Selection: You have a population of possible solutions to a given problem and a fitness function. At every iteration, you evaluate how to fit each solution with your fitness function.\n",
    "- Crossover: Then you select the fittest ones and perform crossover to create a new population.\n",
    "- Mutation: You take those children and mutate them with some random modification and repeat the process until you get the fittest or best solution.\n",
    "\n",
    "Genetic Programming itself is a big topic in computer science but if you wish to go deeper into genetic algorithms, check out this video series.\n",
    "\n",
    "***But how does this all fit into data science?***\n",
    "\n",
    "Well, it turns out that choosing the right machine learning model and all the best hyperparameters for that model is itself an optimization problem for which genetic programming can be used. The Python library tpot built on top of scikit-learn uses genetic programming to optimize your machine learning pipeline. For instance, in machine learning, after preparing your data you need to know what features to input to your model and how you should construct those features. Once you have those features, you input them into your model to train on, and then you tune your hyperparameters to get the optimal results. Instead of doing this all by yourselves through trial and error, TPOT automates these steps for you with genetic programming and outputs the optimal code for you when it's done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Running Example\n",
    "\n",
    "\n",
    "To understand further, you will practice using the tpot library on an open source dataset. The dataset you will be using is MAGIC Gamma Telescope DataSet. The data are generated to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. To get full details about the dataset description check out this link. The dataset has the following attributes/features :\n",
    "\n",
    "**Predictors**\n",
    "\n",
    "1. fLength: continuous *# major axis of ellipse [mm]*\n",
    "2. fWidth: continuous *# minor axis of ellipse [mm]*\n",
    "3. fSize: continuous *# 10-log of sum of content of all pixels [in #phot]*\n",
    "4. fConc: continuous *# ratio of sum of two highest pixels over fSize [ratio]*\n",
    "5. fConc1: continuous *# ratio of highest pixel over fSize [ratio]*\n",
    "6. fAsym: continuous *# distance from the highest pixel to center, projected onto major axis [mm]*\n",
    "7. fM3Long: continuous *# 3rd root of the third moment along major axis [mm]*\n",
    "8. fM3Trans: continuous *# 3rd root of the third moment along minor axis [mm]*\n",
    "9. fAlpha: continuous *# angle of major axis with a vector to origin [deg]*\n",
    "10. fDist: continuous *# distance from the origin to the center of the ellipse [mm]*\n",
    "\n",
    "**Target**\n",
    "\n",
    "11. class: g,h *# gamma (signal), hadron (background) (target variable)*\n",
    "\n",
    "The goal is to classify an observation as *gamma*, which is the desired signal, or *hadron*, which is the background noise, based on the attributes provided.\n",
    "\n",
    "You will start by importing **pandas** and **numpy** libraries to read the data and perform computations on it respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-in Data\n",
    "\n",
    "Use the pandas **read_csv()** function to read the dataset as a DataFrame. Also, specify the parameter **header = None** since the dataset doesn't have column names yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "telescope_data=pd.read_csv('./data/magic04.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the DataFrame using the **head()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1       2       3       4         5        6        7   \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "        8         9  10  \n",
       "0  40.0920   81.8828  g  \n",
       "1   6.3609  205.2610  g  \n",
       "2  76.9600  256.7880  g  \n",
       "3  10.4490  116.7370  g  \n",
       "4   4.6480  356.4620  g  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescope_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give names to the columns of the DataFrame, you can use the attribute columns on the pandas DataFrame and assign it to a list containing the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telescope_data.columns = ['fLength', 'fWidth','fSize','fConc','fConcl','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConcl</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConcl     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescope_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the column names as well in your DataFrame.\n",
    "\n",
    "# Investigating Your Data\n",
    "To get the necessary information about the DataFrame like the number of values in each column, data-type, count, mean, etc., you can use the pandas info() and describe() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19020 entries, 0 to 19019\n",
      "Data columns (total 11 columns):\n",
      "fLength     19020 non-null float64\n",
      "fWidth      19020 non-null float64\n",
      "fSize       19020 non-null float64\n",
      "fConc       19020 non-null float64\n",
      "fConcl      19020 non-null float64\n",
      "fAsym       19020 non-null float64\n",
      "fM3Long     19020 non-null float64\n",
      "fM3Trans    19020 non-null float64\n",
      "fAlpha      19020 non-null float64\n",
      "fDist       19020 non-null float64\n",
      "class       19020 non-null object\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "telescope_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConcl</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.250154</td>\n",
       "      <td>22.180966</td>\n",
       "      <td>2.825017</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>-4.331745</td>\n",
       "      <td>10.545545</td>\n",
       "      <td>0.249726</td>\n",
       "      <td>27.645707</td>\n",
       "      <td>193.818026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.364855</td>\n",
       "      <td>18.346056</td>\n",
       "      <td>0.472599</td>\n",
       "      <td>0.182813</td>\n",
       "      <td>0.110511</td>\n",
       "      <td>59.206062</td>\n",
       "      <td>51.000118</td>\n",
       "      <td>20.827439</td>\n",
       "      <td>26.103621</td>\n",
       "      <td>74.731787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.283500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.941300</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-457.916100</td>\n",
       "      <td>-331.780000</td>\n",
       "      <td>-205.894700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.336000</td>\n",
       "      <td>11.863800</td>\n",
       "      <td>2.477100</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.128475</td>\n",
       "      <td>-20.586550</td>\n",
       "      <td>-12.842775</td>\n",
       "      <td>-10.849375</td>\n",
       "      <td>5.547925</td>\n",
       "      <td>142.492250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.147700</td>\n",
       "      <td>17.139900</td>\n",
       "      <td>2.739600</td>\n",
       "      <td>0.354150</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>4.013050</td>\n",
       "      <td>15.314100</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>17.679500</td>\n",
       "      <td>191.851450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.122175</td>\n",
       "      <td>24.739475</td>\n",
       "      <td>3.101600</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.285225</td>\n",
       "      <td>24.063700</td>\n",
       "      <td>35.837800</td>\n",
       "      <td>10.946425</td>\n",
       "      <td>45.883550</td>\n",
       "      <td>240.563825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334.177000</td>\n",
       "      <td>256.382000</td>\n",
       "      <td>5.323300</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>575.240700</td>\n",
       "      <td>238.321000</td>\n",
       "      <td>179.851000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>495.561000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fLength        fWidth         fSize         fConc        fConcl  \\\n",
       "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
       "mean      53.250154     22.180966      2.825017      0.380327      0.214657   \n",
       "std       42.364855     18.346056      0.472599      0.182813      0.110511   \n",
       "min        4.283500      0.000000      1.941300      0.013100      0.000300   \n",
       "25%       24.336000     11.863800      2.477100      0.235800      0.128475   \n",
       "50%       37.147700     17.139900      2.739600      0.354150      0.196500   \n",
       "75%       70.122175     24.739475      3.101600      0.503700      0.285225   \n",
       "max      334.177000    256.382000      5.323300      0.893000      0.675200   \n",
       "\n",
       "              fAsym       fM3Long      fM3Trans        fAlpha         fDist  \n",
       "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000  \n",
       "mean      -4.331745     10.545545      0.249726     27.645707    193.818026  \n",
       "std       59.206062     51.000118     20.827439     26.103621     74.731787  \n",
       "min     -457.916100   -331.780000   -205.894700      0.000000      1.282600  \n",
       "25%      -20.586550    -12.842775    -10.849375      5.547925    142.492250  \n",
       "50%        4.013050     15.314100      0.666200     17.679500    191.851450  \n",
       "75%       24.063700     35.837800     10.946425     45.883550    240.563825  \n",
       "max      575.240700    238.321000    179.851000     90.000000    495.561000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescope_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out all the features in the DataFrame are continuous in nature. The target variable/feature class is however *categorical*. You can check the counts of each class in the target variable using **value_counts()** method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    12332\n",
       "h     6688\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescope_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally a good idea to randomly **shuffle** the data before starting to avoid any type of ordering in the data. You can rearrange the data in the DataFrame using numpy's **random** and **permutation()** function. To reset the index numbers after the shuffle use **reset_index()** method with **drop = True** as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConcl</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.8794</td>\n",
       "      <td>11.3200</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>-5.3063</td>\n",
       "      <td>16.2199</td>\n",
       "      <td>-5.8341</td>\n",
       "      <td>17.366</td>\n",
       "      <td>103.365</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.2355</td>\n",
       "      <td>14.4987</td>\n",
       "      <td>2.6776</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>-19.2765</td>\n",
       "      <td>-24.6397</td>\n",
       "      <td>14.0640</td>\n",
       "      <td>7.387</td>\n",
       "      <td>188.726</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0793</td>\n",
       "      <td>18.8493</td>\n",
       "      <td>2.4216</td>\n",
       "      <td>0.4356</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>-19.1632</td>\n",
       "      <td>-17.3796</td>\n",
       "      <td>-15.7077</td>\n",
       "      <td>42.506</td>\n",
       "      <td>138.949</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.2156</td>\n",
       "      <td>18.7115</td>\n",
       "      <td>3.0700</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>-1.0962</td>\n",
       "      <td>-22.7595</td>\n",
       "      <td>10.4226</td>\n",
       "      <td>3.400</td>\n",
       "      <td>195.922</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0354</td>\n",
       "      <td>10.9215</td>\n",
       "      <td>2.2028</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>-14.0194</td>\n",
       "      <td>5.5664</td>\n",
       "      <td>-10.1252</td>\n",
       "      <td>36.275</td>\n",
       "      <td>154.261</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fLength   fWidth   fSize   fConc  fConcl    fAsym  fM3Long  fM3Trans  \\\n",
       "0  20.8794  11.3200  2.6449  0.6138  0.3409  -5.3063  16.2199   -5.8341   \n",
       "1  33.2355  14.4987  2.6776  0.3782  0.2048 -19.2765 -24.6397   14.0640   \n",
       "2  25.0793  18.8493  2.4216  0.4356  0.2330 -19.1632 -17.3796  -15.7077   \n",
       "3  47.2156  18.7115  3.0700  0.2119  0.1213  -1.0962 -22.7595   10.4226   \n",
       "4  13.0354  10.9215  2.2028  0.7586  0.4545 -14.0194   5.5664  -10.1252   \n",
       "\n",
       "   fAlpha    fDist class  \n",
       "0  17.366  103.365     h  \n",
       "1   7.387  188.726     g  \n",
       "2  42.506  138.949     g  \n",
       "3   3.400  195.922     g  \n",
       "4  36.275  154.261     g  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telescope_shuffle=telescope_data.iloc[np.random.permutation(len(telescope_data))]\n",
    "tele=telescope_shuffle.reset_index(drop=True)\n",
    "tele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Your Target\n",
    "\n",
    "Before using tpot, it is essential you do the labeling of categorical variables in your DataFrame. To learn more about labeling categorical variables check out this tutorial. Here only the target variable class is the *categorical* feature, hence the treatment should be done to that column. \n",
    "\n",
    "You will replace the **g** class (signal) with a numerical value **0** and **h** class (background) with numerical value **1**. This can be achieved via **map()** function with the argument as a dictionary which holds the respective mapping of the classes of the target variable.\n",
    "\n",
    "**NOTE:** in practice, this is usually done by the [label encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) or [one-hot encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) provided with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConcl</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.8794</td>\n",
       "      <td>11.3200</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>-5.3063</td>\n",
       "      <td>16.2199</td>\n",
       "      <td>-5.8341</td>\n",
       "      <td>17.366</td>\n",
       "      <td>103.365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.2355</td>\n",
       "      <td>14.4987</td>\n",
       "      <td>2.6776</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>-19.2765</td>\n",
       "      <td>-24.6397</td>\n",
       "      <td>14.0640</td>\n",
       "      <td>7.387</td>\n",
       "      <td>188.726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0793</td>\n",
       "      <td>18.8493</td>\n",
       "      <td>2.4216</td>\n",
       "      <td>0.4356</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>-19.1632</td>\n",
       "      <td>-17.3796</td>\n",
       "      <td>-15.7077</td>\n",
       "      <td>42.506</td>\n",
       "      <td>138.949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.2156</td>\n",
       "      <td>18.7115</td>\n",
       "      <td>3.0700</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>-1.0962</td>\n",
       "      <td>-22.7595</td>\n",
       "      <td>10.4226</td>\n",
       "      <td>3.400</td>\n",
       "      <td>195.922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0354</td>\n",
       "      <td>10.9215</td>\n",
       "      <td>2.2028</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>-14.0194</td>\n",
       "      <td>5.5664</td>\n",
       "      <td>-10.1252</td>\n",
       "      <td>36.275</td>\n",
       "      <td>154.261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fLength   fWidth   fSize   fConc  fConcl    fAsym  fM3Long  fM3Trans  \\\n",
       "0  20.8794  11.3200  2.6449  0.6138  0.3409  -5.3063  16.2199   -5.8341   \n",
       "1  33.2355  14.4987  2.6776  0.3782  0.2048 -19.2765 -24.6397   14.0640   \n",
       "2  25.0793  18.8493  2.4216  0.4356  0.2330 -19.1632 -17.3796  -15.7077   \n",
       "3  47.2156  18.7115  3.0700  0.2119  0.1213  -1.0962 -22.7595   10.4226   \n",
       "4  13.0354  10.9215  2.2028  0.7586  0.4545 -14.0194   5.5664  -10.1252   \n",
       "\n",
       "   fAlpha    fDist  class  \n",
       "0  17.366  103.365      1  \n",
       "1   7.387  188.726      0  \n",
       "2  42.506  138.949      0  \n",
       "3   3.400  195.922      0  \n",
       "4  36.275  154.261      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tele['class']=tele['class'].map({'g':0,'h':1})\n",
    "tele.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you store the class labels, which you need to predict, in a separate variable *tele_class*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tele_class = tele['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIssing Value Handling\n",
    "\n",
    "You should also do missing value treatment before using *tpot*. To check the number of missing values column-wise, you can execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fLength     False\n",
       "fWidth      False\n",
       "fSize       False\n",
       "fConc       False\n",
       "fConcl      False\n",
       "fAsym       False\n",
       "fM3Long     False\n",
       "fM3Trans    False\n",
       "fAlpha      False\n",
       "fDist       False\n",
       "class       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(tele).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset doesn't have any missing values. Note in datasets with missing values you can either drop the rows/columns using dropna() method or replace the missing value with some dummy value using fillna() method. For example, the following chunk of code will replace the NA values with a dummy value -999."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tele = tele.fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now split the DataFrame into a training set and a testing set just like you do while doing any type of machine learning modeling. You can do this via sklearn's **cross_validation** **train_test_split**. The parameters are tele.index as indexes of the DataFrame, *train_size = 0.75* to keep 75% of the data in training set, *test_size = 0.25* to keep the rest 25% data in testing set and stratify = tele_class the class label's values in the dataset. Note the validation set is just to give us an idea of the test set error. Here it is kept to be the same as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_indices, testing_indices = train_test_split(tele.index,\n",
    "                                                        stratify = tele_class,\n",
    "                                                        train_size=0.75, test_size=0.25, random_state = 2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the size of the training set and validation set using the size attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14265, 4755)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_indices.size, testing_indices.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to use the **tpot** library to suggest us the best pipeline for this binary classification problem. To do so, you have to import **TPOTClassifier** class from the tpot library. Had this been a regression problem you would have imported **TPOTRegressor** class.\n",
    "\n",
    "**TPOTClassifier** has a wide variety of parameters, and you can read all about them here. But the most notable ones you must know are:\n",
    "\n",
    "- generations: Number of iterations to the run pipeline optimization process. The default is 100.\n",
    "- population_size: Number of individuals to retain in the genetic programming population every generation. The default is 100.\n",
    "- offspring_size: Number of offspring to produce in each genetic programming generation. The default is 100.\n",
    "- mutation_rate: Mutation rate for the genetic programming algorithm in the range [0.0, 1.0]. This parameter tells the GP algorithm how many pipelines to apply random changes to every generation. Default is 0.9\n",
    "- crossover_rate: Crossover rate for the genetic programming algorithm in the range [0.0, 1.0]. This parameter tells the genetic programming algorithm how many pipelines to \"breed\" every generation.\n",
    "- scoring: Function used to evaluate the quality of a given pipeline for the classification problem like accuracy, average_precision, roc_auc, recall, etc. The default is accuracy.\n",
    "- cv: Cross-validation strategy used when evaluating pipelines. The default is 5.\n",
    "- random_state: The seed of the pseudo-random number generator used in TPOT. Use this parameter to make sure that TPOT will give you the same results each time you run it against the same data set with that seed.\n",
    "\n",
    "Also note mutation_rate + crossover_rate cannot exceed **1.0**.\n",
    "\n",
    "Here you will use tpot with generations = 5 and the rest of the parameters at default values. The parameter verbosity = 2 states how much information TPOT communicates while it's running.\n",
    "\n",
    "Then you will call the **fit()** method with the training set (without the target column) and the target column as the arguments.\n",
    "\n",
    "Note running the code in the below cell will take several hours to finish. With the given TPOT settings (5 generations with 100 population size), TPOT will evaluate 500 pipeline configurations before finishing. To put this number into context, think about a grid search of 500 hyperparameter combinations for a machine learning algorithm and how long that grid search will take. That is 500 model configurations to evaluate with 5-fold cross-validation, which means that roughly 2500 models are fit and evaluated on the training data in one grid search. That's a time-consuming procedure! Later, you will get to know about some more arguments that you can pass to TPOTClassifier to control the execution time for TPOT to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "tpot = TPOTClassifier(generations=5,verbosity=2)\n",
    "\n",
    "tpot.fit(tele.drop('class',axis=1).loc[training_indices].values,\n",
    "         tele.loc[training_indices,'class'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, 5 generations were computed, each giving the training efficiency of the fitting model on the training set. As evident, the best pipeline is the one that has the CV accuracy score of **88.12%**. The model that produces this result is the pipeline, consisting of pre-processing techniques like PloynomialFeatures and then RobustScaler that adds synthetic features to the input data and normalizes them, which then get utilized by a Gradient Boosting classifier to form the final predictions. You can also notice that tpot gives various hyper-parameter values like learning_rate,max_depth, etc., also along with the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88012618296529965"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(tele.drop('class',axis=1).loc[testing_indices].values,\n",
    "           tele.loc[testing_indices, 'class'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the test accuracy is **88.14%.**\n",
    "\n",
    "Finally, you can tell TPOT to export the corresponding Python code for the optimized pipeline to a text file with the export function:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tpot.export('tpot_MAGIC_Gamma_Telescope_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't that awesome? Without you tweaking a lot of parameters and options to get the best model, TPOT not only gave you the information about the best model but also a working code for it!\n",
    "\n",
    "As indicated earlier, the last TPOT run took *several hours* to finish. Well, there are certain parameters you can specify to control the execution time of TPOT but with a trade-off. Since you will be limiting the time of TPOT execution, TPOT won't be able to explore all the possible pipelines and hence the best model suggested by TPOT at the end of the constrained time limit may not be the best model possible for that dataset. \n",
    "\n",
    "However, if sufficient time is given it will be somewhat closer to the best possible model. Some parameters are:\n",
    "\n",
    "- **max_time_mins**: how many minutes TPOT has to optimize the pipeline. If not None, this setting will override the generations parameter and allow TPOT to run until max_time_mins minutes elapse.\n",
    "- **max_eval_time_mins**: how many minutes TPOT has to evaluate a single pipeline. Setting this parameter to higher values will enable TPOT to evaluate more complex pipelines, but will also allow TPOT to run longer. Use this parameter to help prevent TPOT from wasting time on assessing time-consuming pipelines. The default is 5.\n",
    "- **early_stop**: how many generations TPOT checks whether there is no improvement in the optimization process. Ends the optimization process if there is no improvement in the given number of generations.\n",
    "- **n_jobs**: Number of procedures to use in parallel for evaluating pipelines during the TPOT optimization process. Setting n_jobs=-1 will use as many cores as available on the computer. Beware that using multiple methods on the same machine may cause memory issues for large datasets. The default is 1.\n",
    "- **subsample**: Fraction of training samples that are used during the TPOT optimization process. Must be in the range (0.0, 1.0]. The default is 1.\n",
    "\n",
    "Just for practice, you will again run TPOT with additional arguments max_time_mins = 2 and max_eval_time_mins = 0.04 but this time with reduced population_size = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8281811731066163\n",
      "Generation 2 - Current best internal CV score: 0.8467575945563388\n",
      "Generation 3 - Current best internal CV score: 0.8654739243774452\n",
      "Generation 4 - Current best internal CV score: 0.8654739243774452\n",
      "Generation 5 - Current best internal CV score: 0.8654739243774452\n",
      "Generation 6 - Current best internal CV score: 0.8729749730857256\n",
      "Generation 7 - Current best internal CV score: 0.8729749730857256\n",
      "\n",
      "2.009534283333333 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.5, max_depth=2, min_child_weight=15, n_estimators=100, nthread=1, subsample=0.9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=None, generations=1000000,\n",
       "        max_eval_time_mins=0.04, max_time_mins=2, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=15,\n",
       "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(verbosity=2, max_time_mins=2, max_eval_time_mins=0.04, population_size=15)\n",
    "tpot.fit(tele.drop('class',axis=1).loc[training_indices].values, tele.loc[training_indices,'class'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can notice the best performing classifier within the time frame specified is now XGBoost with SelectPercentile() and RobustScaler() as the pre-processing steps. But you notice that the accurracy declined to 87.29%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "\n",
    "- **TPOT can take a long time to finish its search**\n",
    "\n",
    "Running TPOT isn’t as simple as fitting one model on the dataset. It is considering multiple machine learning algorithms (random forests, linear models, SVMs, etc.) in a pipeline with numerous preprocessing steps (missing value imputation, scaling, PCA, feature selection, etc.), the hyper-parameters for all of the models and preprocessing steps, as well as multiple ways to ensemble or stack the algorithms within the pipeline. That’s why it usually takes a long time to execute and isn’t feasible for large datasets.\n",
    "\n",
    "- **TPOT can recommend different solutions for the same dataset**\n",
    "\n",
    "If you're working with a reasonably complex dataset or run TPOT for a short amount of time, different TPOT runs may result in different pipeline recommendations. When two TPOT runs recommend different pipelines, this means that the TPOT runs didn't converge due to lack of time or that multiple pipelines perform more-or-less the same on your dataset.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Hurray! You have come to the end of this tutorial. You started with a little introduction about the idea behind Automated Machine Learning platforms. Then you explored a bit on Genetic Programming and how TPOT uses it to automate the machine learning pipeline building process. You also practiced using the TPOT library in Python on a dataset along with gaining knowledge about the functions it provides. If you plan to use TPOT in the future, I strongly suggest you look at its excellent [documentation](http://epistasislab.github.io/tpot/). Happy Exploring!\n",
    "\n",
    "If you would like to learn more about Machine Learning in Python, take DataCamp's [Machine Learning with Tree-Based Models in Python](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python) course.\n",
    "\n",
    "The following web pages were used as sources in writing this tutorial.\n",
    "\n",
    "- [Classification](http://epistasislab.github.io/tpot/api/)\n",
    "- [What to expect from AutoML software](https://epistasislab.github.io/tpot/using/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
